{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c96f31a",
   "metadata": {},
   "source": [
    "# Lab 1: Silver Fund Quant Data Module and Returns\n",
    "\n",
    "In this lab we will:\n",
    "- Explore how to pull data from the Silver Fund Quant data module.\n",
    "- Demonstrate the different properties of returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a980b29",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to have a smooth experience with this lab do the following:\n",
    "\n",
    "### 1. Log into the Fulton Super Computer.\n",
    "\n",
    "In order to log into you must have an account at [https://rc.byu.edu/](https://rc.byu.edu/) and be added to the `grp_quant` group by Brian Boyer.\n",
    "\n",
    "It can take some time to get approved so make sure to create an account and reach out to Brian promptly.\n",
    "\n",
    "### 2. Clone this repo to the desired location (I prefer to have a `Projects` folder where I keep all of my repositories).\n",
    "\n",
    "Clone the repo by running\n",
    "```bash\n",
    "git clone https://github.com/BYUSilverFund/sf-quant-labs.git\n",
    "```\n",
    "\n",
    "### 3. Install `uv` (Package Manager)\n",
    "\n",
    "We use `uv` to create and manage virtual environments.\n",
    "\n",
    "To install `uv` run\n",
    "\n",
    "```bash\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "```\n",
    "\n",
    "Check that `uv` is installed by running\n",
    "\n",
    "```bash\n",
    "uv --version\n",
    "```\n",
    "\n",
    "If this returns an error you might need to add uv to your path. Run:\n",
    "\n",
    "```bash\n",
    "source $HOME/.local/bin/env\n",
    "```\n",
    "\n",
    "Restart your terminal for the changes to take effect.\n",
    "\n",
    "### 4. Create a Virtual Environment\n",
    "\n",
    "The virtual environment will make it so that we have consistent package and Python versions across all devices.\n",
    "\n",
    "With `uv` it is really easy to create a virtual environment with synced dependencies.\n",
    "\n",
    "Just run\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "Activate the environment by running\n",
    "\n",
    "``` bash\n",
    "source .venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46266d32",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "With all of the setup out of the way we will import the necessary Python packages for the lab.\n",
    "\n",
    "- `sf_quant`: Silver Fund Quant Team package that includes modules for loading data, optimizing portfolios, backtesting, and analyzing performance.\n",
    "- `datetime`: Native Python library for creating Python `date` types.\n",
    "- `polars`: Data frame library similar to Pandas but with a much cleaner API and 100x speed ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e509698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sf_quant as sf\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e2772",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8a82f",
   "metadata": {},
   "source": [
    "View all available columns by running sf.data.get_assets_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca909b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shape: (32, 2)\\n┌─────────────────────────────────┬─────────┐\\n│ column                          ┆ dtype   │\\n│ ---                             ┆ ---     │\\n│ str                             ┆ str     │\\n╞═════════════════════════════════╪═════════╡\\n│ barrid                          ┆ String  │\\n│ date                            ┆ Date    │\\n│ instrument                      ┆ String  │\\n│ iso_country_code                ┆ String  │\\n│ iso_currency_code               ┆ String  │\\n│ issuerid                        ┆ String  │\\n│ name                            ┆ String  │\\n│ rootid                          ┆ String  │\\n│ average_daily_bid_ask_spread_3… ┆ Float64 │\\n│ average_daily_bid_ask_spread_6… ┆ Float64 │\\n│ average_daily_bid_ask_spread_9… ┆ Float64 │\\n│ average_daily_volume_30         ┆ Float64 │\\n│ average_daily_volume_60         ┆ Float64 │\\n│ average_daily_volume_90         ┆ Float64 │\\n│ bid_ask_spread                  ┆ Float64 │\\n│ currency                        ┆ String  │\\n│ cusip                           ┆ String  │\\n│ daily_volume                    ┆ Float64 │\\n│ historical_beta                 ┆ Float64 │\\n│ in_universe                     ┆ Boolean │\\n│ market_cap                      ┆ Float64 │\\n│ predicted_beta                  ┆ Float64 │\\n│ price                           ┆ Float64 │\\n│ price_source                    ┆ String  │\\n│ return                          ┆ Float64 │\\n│ russell_1000                    ┆ Boolean │\\n│ russell_2000                    ┆ Boolean │\\n│ specific_return                 ┆ Float64 │\\n│ specific_risk                   ┆ Float64 │\\n│ ticker                          ┆ String  │\\n│ total_risk                      ┆ Float64 │\\n│ yield                           ┆ Float64 │\\n└─────────────────────────────────┴─────────┘'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.data.get_assets_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf59f4",
   "metadata": {},
   "source": [
    "Use the following code to pull data for our investment universe from 2024-01-01 to 2024-12-31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df5bc083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (739_726, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>barrid</th><th>return</th></tr><tr><td>date</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>2024-01-02</td><td>&quot;USA06Z1&quot;</td><td>-10.2623</td></tr><tr><td>2024-01-03</td><td>&quot;USA06Z1&quot;</td><td>-1.2071</td></tr><tr><td>2024-01-04</td><td>&quot;USA06Z1&quot;</td><td>-0.1929</td></tr><tr><td>2024-01-05</td><td>&quot;USA06Z1&quot;</td><td>0.5155</td></tr><tr><td>2024-01-08</td><td>&quot;USA06Z1&quot;</td><td>5.3846</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2024-12-24</td><td>&quot;USBQOR1&quot;</td><td>2.5872</td></tr><tr><td>2024-12-26</td><td>&quot;USBQOR1&quot;</td><td>4.293</td></tr><tr><td>2024-12-27</td><td>&quot;USBQOR1&quot;</td><td>-5.108</td></tr><tr><td>2024-12-30</td><td>&quot;USBQOR1&quot;</td><td>-4.2663</td></tr><tr><td>2024-12-31</td><td>&quot;USBQOR1&quot;</td><td>-1.6749</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (739_726, 3)\n",
       "┌────────────┬─────────┬──────────┐\n",
       "│ date       ┆ barrid  ┆ return   │\n",
       "│ ---        ┆ ---     ┆ ---      │\n",
       "│ date       ┆ str     ┆ f64      │\n",
       "╞════════════╪═════════╪══════════╡\n",
       "│ 2024-01-02 ┆ USA06Z1 ┆ -10.2623 │\n",
       "│ 2024-01-03 ┆ USA06Z1 ┆ -1.2071  │\n",
       "│ 2024-01-04 ┆ USA06Z1 ┆ -0.1929  │\n",
       "│ 2024-01-05 ┆ USA06Z1 ┆ 0.5155   │\n",
       "│ 2024-01-08 ┆ USA06Z1 ┆ 5.3846   │\n",
       "│ …          ┆ …       ┆ …        │\n",
       "│ 2024-12-24 ┆ USBQOR1 ┆ 2.5872   │\n",
       "│ 2024-12-26 ┆ USBQOR1 ┆ 4.293    │\n",
       "│ 2024-12-27 ┆ USBQOR1 ┆ -5.108   │\n",
       "│ 2024-12-30 ┆ USBQOR1 ┆ -4.2663  │\n",
       "│ 2024-12-31 ┆ USBQOR1 ┆ -1.6749  │\n",
       "└────────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = dt.date(2024, 1, 1) # TODO: create 2024-01-01 using the datetime library\n",
    "end = dt.date(2024, 12, 31) # TODO: create 2024-12-31 using the datetime library\n",
    "\n",
    "columns = [\n",
    "    'date',\n",
    "    'barrid',\n",
    "    'return'\n",
    "    # NOTE: You can view all available columns by running sf.data.get_assets_columns() in another cell\n",
    "]\n",
    "\n",
    "df = sf.data.load_assets(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    in_universe=True,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fca7cd",
   "metadata": {},
   "source": [
    "## Log returns\n",
    "\n",
    "### Instructions\n",
    "1. Compute the log returns for each asset.\n",
    "2. Compute the cumulative log returns for each asset.\n",
    "3. Run the assertion cell to make sure your results are correct.\n",
    "\n",
    "Make sure to sort prior to computing time series metrics and use `.over()` apply the computation in groups.\n",
    "\n",
    "Log returns have the nice property of being additive. Use this to your advantage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325acff5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sf_quant' has no attribute 'np'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df.head())\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df_log = \u001b[43mtask_compute_log_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m df_log\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtask_compute_log_returns\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtask_compute_log_returns\u001b[39m(df: pl.DataFrame) -> pl.DataFrame:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Compute the log returns for each security and date combo.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33;03m        pl.DataFrame: Data frame containing columns date, barrid, return, and log_return\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mlog_return\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnp\u001b[49m.log(df[\u001b[33m'\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df.head())\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'sf_quant' has no attribute 'np'"
     ]
    }
   ],
   "source": [
    "def task_compute_log_returns(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the log returns for each security and date combo.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Data frame containing columns date, barrid, and return\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing columns date, barrid, return, and log_return\n",
    "    \"\"\"\n",
    "\n",
    "    df['log_return'] = sf.np.log(df['return'])\n",
    "    print(df.head())\n",
    "\n",
    "    pass\n",
    "\n",
    "df_log = task_compute_log_returns(df)\n",
    "\n",
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca93d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'df' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df_cum_log = \u001b[43mtask_compute_cumulative_log_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m df_cum_log\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtask_compute_cumulative_log_returns\u001b[39m\u001b[34m(df_log)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtask_compute_cumulative_log_returns\u001b[39m(df_log: pl.DataFrame) -> pl.DataFrame:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Compute the cummulative log returns for each security and date combo.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33;03m        pl.DataFrame: Data frame containing columns date, barrid, return, log_return, and cumulative_log_return\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     df = \u001b[43mdf\u001b[49m.with_columns((pl.col(\u001b[33m'\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m'\u001b[39m).log().alias(\u001b[33m\"\u001b[39m\u001b[33mlog_return\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'df' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "def task_compute_cumulative_log_returns(df_log: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the cummulative log returns for each security and date combo.\n",
    "\n",
    "    Args:\n",
    "        df_log (pl.DataFrame): Data frame containing columns date, barrid, return, and log_return\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing columns date, barrid, return, log_return, and cumulative_log_return\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (pl.col('return').log().alias(\"log_return\"))\n",
    "        )\n",
    "    print(df)\n",
    "\n",
    "    pass\n",
    "\n",
    "df_cum_log = task_compute_cumulative_log_returns(df_log)\n",
    "\n",
    "df_cum_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = df_cum_log['cumulative_log_return'].max()\n",
    "expected = 2.8475532093020557\n",
    "assert abs(expected - val) < 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8215914b",
   "metadata": {},
   "source": [
    "## Compounded Returns\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Compute the cumulative compounded returns for each asset.\n",
    "2. Run the assertion to check that your results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_cumulative_compounded_returns(df_cum_log: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the cumulative compounded net returns for each security.\n",
    "\n",
    "    Args:\n",
    "        df_cum_log (pl.DataFrame): Data frame containing columns date, barrid, return, log_return, and cumulative_log_return\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing columns date, barrid, return, log_return, cumulative_log_return, and cumulative_compounded_return\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Finish this function\n",
    "\n",
    "    pass\n",
    "\n",
    "df_cum_comp = task_compute_cumulative_compounded_returns(df_cum_log)\n",
    "\n",
    "df_cum_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfe073",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df_cum_comp['cumulative_compounded_return'].max()\n",
    "expected = 16.245533963705515\n",
    "assert abs(value - expected ) < 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e5907",
   "metadata": {},
   "source": [
    "## Exponentiation\n",
    "\n",
    "Note that the max cumulative log return is different from the cumulative compounded return.\n",
    "\n",
    "Why is that?\n",
    "\n",
    "The answer is that the cumulative log return is still in log space!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Exponentiate the cumulative log returns to put them back into the original space.\n",
    "2. Check that the exponentiated returns match the cumulative compounded returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22518ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_exponentiate_returns(df_cum_comp: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Exponentiate the cumulative log returns and convert back to net.\n",
    "\n",
    "    Args:\n",
    "        df_cum_comp: Data frame containing date, barrid, return, log_return, cumulative_log_return, and cumulative_compouned_return.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing all previous columns plus exponentiated_return\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Finish this function\n",
    "\n",
    "    pass\n",
    "\n",
    "df_exp = task_exponentiate_returns(df_cum_comp)\n",
    "\n",
    "df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df_exp['cumulative_compounded_return'].max() - df_exp['exponentiated_return'].max()\n",
    "\n",
    "assert abs(value) < 1e-9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
